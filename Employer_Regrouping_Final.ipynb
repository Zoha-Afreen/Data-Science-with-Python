{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9e16891",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "532174d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\zafreen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import warnings\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('wordnet')\n",
    "from fuzzywuzzy import fuzz\n",
    "warnings.filterwarnings('ignore')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926c2ff6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9280, 1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=pd.read_csv('C:/Users/zafreen/Downloads/ENS/Prev_Emp_Starts.csv')\n",
    "list_uni=df1['Previous Employer'].unique().tolist()\n",
    "df1=pd.DataFrame(list_uni,columns=['Company'])         \n",
    "df1=df1.reset_index(drop=True)\n",
    "df1['Company']=df1['Company'].astype(str)\n",
    "df1.head(93)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f63fadfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[iqvia, biotech]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[infor, geac, computer]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[livestyle, sfx, entertainment]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[k, line, america]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gotjunk]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>[adc, telecommunication, adc]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>[adesa, kar, auction]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>[adp, automatic, data, processing]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>[adp, automatic, data, processing, adp]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>[adp, dealer, canada, cdk, global, canada]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>95 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Company\n",
       "0                             [iqvia, biotech]\n",
       "1                      [infor, geac, computer]\n",
       "2              [livestyle, sfx, entertainment]\n",
       "3                           [k, line, america]\n",
       "4                                    [gotjunk]\n",
       "..                                         ...\n",
       "90               [adc, telecommunication, adc]\n",
       "91                       [adesa, kar, auction]\n",
       "92          [adp, automatic, data, processing]\n",
       "93     [adp, automatic, data, processing, adp]\n",
       "94  [adp, dealer, canada, cdk, global, canada]\n",
       "\n",
       "[95 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "vendor_stopwords=['biz', 'bv', 'co', 'comp', 'company','com', \n",
    "                'corp','corporation', 'dba', \n",
    "                'inc', 'incorp', 'incorporat', \n",
    "                'incorporate', 'incorporated', 'incorporation', \n",
    "                'international', 'intl', 'intnl', \n",
    "                'limited' ,'llc', 'ltd', 'llp', \n",
    "                'machines', 'pvt', 'pte', 'private', 'unknown','Agency','and','Assn','Assoc','Associates','Association','Bank','BV','Co','Comp','Company','Corp',\n",
    "             'Corporation', 'Corpn','Enterprises','Gmbh','Group','Hotel','Hotels','Infotech', 'Info', 'infotech',\n",
    "             'info','info tech', 'Info tech', 'Info Tech', 'Inc','Incorporated','International','Intl','Limited',\n",
    "             'LLC','LLP','LP','Ltd','Manufacturing','Mfg','PA','PC','Pharmacy','PLC','PLLC','Restaurant','SA',\n",
    "             'Sales','Service','Services','Store','Svcs','Travel','Unlimited', 'agency','and','assn','assoc',\n",
    "             'associates','association','bank','bv','co','comp','company','corp','corporation', 'corpn',\n",
    "             'enterprises','gmbh','group','hotel','hotels','inc','incorporated','international','intl','limited',\n",
    "             'llc','llp','lp','ltd','manufacturing','mfg','pa','pc','pharmacy','plc','pllc','restaurant','sa',\n",
    "             'sales','service','services','store','svcs','travel','unlimited']\n",
    "#vinod\n",
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z\\s]+' if not remove_digits else r'[^a-zA-z0\\s]+'\n",
    "    #use reqex\n",
    "    #https://dataschool.com/how-to-teach-people-sql/how-regex-works-in-sql/\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "def remove_stopwords(text):\n",
    "    text=\" \".join([char for char in text if char not in vendor_stopwords])\n",
    "    #concat\n",
    "    return text\n",
    "def tokenise(text):\n",
    "    text=re.split(\"\\W+\",text)\n",
    "    #string split\n",
    "    return text\n",
    "\n",
    "df1['Company']=df1['Company'].apply(lambda x :remove_special_characters(x) )\n",
    "df1['Company']=df1['Company'].apply(lambda x: x.lower())\n",
    "df1['Company']=df1['Company'].apply(lambda x :x.strip() )\n",
    "df1['Company']=df1['Company'].apply(lambda x :x.strip(\"[]\") )\n",
    "df1['Company']=df1['Company'].apply(lambda x:tokenise(x))\n",
    "df1['Company']=df1['Company'].apply(lambda x:remove_stopwords(x))\n",
    "df1['Company']=df1['Company'].apply(lambda x:tokenise(x))\n",
    "#run all functions\n",
    "df1=df1.dropna()\n",
    "df1.head(95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "573fc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.dropna()\n",
    "#select with where\n",
    "df1=df1[df1['Company'] !='[]']\n",
    "#select with where\n",
    "df1=df1.reset_index(drop=True)\n",
    "df1['Company']=df1.sort_values(by=\"Company\")[4:]\n",
    "#sort\n",
    "df1=df1.dropna()\n",
    "#select with where\n",
    "df1=df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc0e2fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df1)):\n",
    "    #vinod\n",
    "    if len(df1['Company'][i])>1:\n",
    "        df1.loc[i,'Company']=df1['Company'][i][0]+\" \"+df1['Company'][i][1]\n",
    "    else:\n",
    "        df1.loc[i,'Company']=df1['Company'][i][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c8c5df",
   "metadata": {},
   "source": [
    "# Steps in details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6204a8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given : letters,first_letter,to_remove are lists\n",
    "#         to_replace is a dictionary with key value pair.\n",
    "        \n",
    "# Step 1: for every character in query it checks if it is alphabet. if yes it will store in a list called letters\n",
    "#         Eg: query=\"Oracle 3Corp\" letters=\"Oracle Corp\".\n",
    "# Step 2: it checks the length of query. if it is  equal to 1 then append 3 zeros to query\n",
    "#         Eg: query=\"a\" then query should be changed to \"a000\".\n",
    "# Step 3: create a list called to_remove=('a', 'e', 'i', 'o', 'u', 'y', 'h', 'w')\n",
    "# Step 4: assign first letter of letters list in a variable called first_letter\n",
    "# Step 5: delete first letter from letters list\n",
    "# Step 6: remove the characters from letters if they are among the characters in to_remove\n",
    "# Step 7: Now check the length of letters list if it is qqual to zero them return 3 zerots as output of soundex\n",
    "# Step 8: else continue\n",
    "# Step 9: create a list called to_replace ={('b'): 1,('p'):2, ('c'):3, ('g'):4, ('j'):5, ('k'):6, ('q'):7, ('s'):8, ('z'): 9,\n",
    "#                    ('d'):11, ('t'):12, ('l'): 13, ('m'):14, ('r',): 15,('f'):16,('v'):17,('x'):18, ('n'): 19}\n",
    "# Step 10: attach first_letter to corresponding code created from remaining alphabet after removing vowels from to _remove\n",
    "#          Eg: \"Amazon\" step1: choose \"A\",step2: remove a,a,o to get \"mzn\", step3 code m,z,n,step4 attach code to A=\"A14919\"\n",
    "# Step 13:for index,char in letters\n",
    "#         if index is equal to\n",
    "#         (length of letters)-1 or (index+1is less than len(letters) and char is not equal to letters of index+1)\n",
    "#         then save such characters in letters\n",
    "# Step 14:if first_letter is equal to first letter of list letters then assign first_letter of query as first letter of letters \n",
    "# Step 15:else enter the first value o query as first value of letters.\n",
    "# Step 16: repeat Step 4 and Step 5\n",
    "# Step 17: for every character in letters check if it is an integer and store it back in letters \n",
    "# Step 18: take only 3 characters of letters.\n",
    "# Step 19: while length of letters is less than 3 ,Append 3 zeros if result contains less than 3 digits.\n",
    "# Step 20: insert first_letter as first value of letters \n",
    "# Step 21: join each value in letters with no space in between and return the value as output of the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95fc888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define soundex\n",
    "def soundex(query: str):\n",
    "    #Clean up the query string\n",
    "    #query = query\n",
    "    letters = [char for char in query if char.isalpha()]\n",
    "    # If query contains only 1 letter, return query+\"000\" (Refer step 5)\n",
    "    if len(query) == 1:\n",
    "        #if else\n",
    "        return query + \"000\"\n",
    "    to_remove = ('a', 'e', 'i', 'o', 'u', 'y', 'h', 'w')    \n",
    "    # Save the first letter. Remove all occurrences of a, e, i, o, u, y, h, w.\n",
    "    first_letter = letters[0]\n",
    "    #assign 1st char \n",
    "    letters = letters[1:]\n",
    "    # assign rest char\n",
    "    letters = [char for char in letters if char not in to_remove]\n",
    "              # (select char from letters where letters not in(select * from to_remove)\n",
    "    if len(letters) == 0:\n",
    "        #if else\n",
    "        return first_letter + \"000\"\n",
    "    # Step 2: Replace all consonants (include the first letter) with digits according to rules\n",
    "    to_replace ={('b'): 1,('p'):2, ('c'):3, ('g'):4, ('j'):5, ('k'):6, ('q'):7, ('s'):8, ('z'): 9,\n",
    "                   ('d'):11, ('t'):12, ('l'): 13, ('m'):14, ('r',): 15,('f'):16,('v'):17,('x'):18, ('n'): 19}\n",
    "    first_letter = [value if first_letter else first_letter for group, value in to_replace.items() if first_letter in group]\n",
    "    letters = [value if char else char\n",
    "               for char in letters\n",
    "               for group, value in to_replace.items()\n",
    "               if char in group]\n",
    "    #Replace all adjacent same digits with one digit.\n",
    "    letters = [char for ind, char in enumerate(letters)\n",
    "               if (ind == len(letters) - 1 or (ind+1 < len(letters) and char != letters[ind+1]))]\n",
    "    # If the saved letterâ€™s digit is the same the resulting first digit, remove the digit (keep the letter)\n",
    "    if first_letter == letters[0]:\n",
    "        letters[0] = query[0]\n",
    "    else:\n",
    "        letters.insert(0, query[0])\n",
    "    # Remove all except first letter and 3 digits after it.\n",
    "    first_letter = letters[0]\n",
    "    letters = letters[1:]\n",
    "    letters = [char for char in letters if isinstance(char, int)][0:3]\n",
    "    # Append 3 zeros if result contains less than 3 digits.\n",
    "    while len(letters) < 3:\n",
    "        letters.append(0)\n",
    "    #append in sql\n",
    "    letters.insert(0, first_letter)\n",
    "    string = \"\".join([str(l) for l in letters])\n",
    "    #concate\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00a5b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Amazon=mzn=14919"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20582814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soundex(query: str):\n",
    "    #Clean up the query string\n",
    "    #query = query\n",
    "    letters = [char for char in query if char.isalpha()]\n",
    "    # If query contains only 1 letter, return query+\"000\" (Refer step 5)\n",
    "    if len(query) == 1:\n",
    "        #if else\n",
    "        return query + \"000\"\n",
    "    to_remove = ('a', 'e', 'i', 'o', 'u', 'y', 'h', 'w')    \n",
    "    # Save the first letter. Remove all occurrences of a, e, i, o, u, y, h, w.\n",
    "    first_letter = letters[0]\n",
    "    #assign 1st char \n",
    "    letters = letters[1:]\n",
    "    # assign rest char\n",
    "    letters = [char for char in letters if char not in to_remove]\n",
    "              # (select char from letters where letters not in(select * from to_remove)\n",
    "    if len(letters) == 0:\n",
    "        #if else\n",
    "        return first_letter + \"000\"\n",
    "    # Step 2: Replace all consonants (include the first letter) with digits according to rules\n",
    "    to_replace ={('b'): 1,('p'):2, ('c'):3, ('g'):4, ('j'):5, ('k'):6, ('q'):7, ('s'):8, ('z'): 9,\n",
    "                   ('d'):11, ('t'):12, ('l'): 13, ('m'):14, ('r',): 15,('f'):16,('v'):17,('x'):18, ('n'): 19}\n",
    "    first_letter = [value if first_letter else first_letter for group, value in to_replace.items()\n",
    "                    if first_letter in group]\n",
    "    print(first_letter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc53e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_name_std(data_t):\n",
    "        data_tf=pd.DataFrame()\n",
    "        #create table data\n",
    "        for cluster in data_t['code_0'].unique():\n",
    "            #vinod\n",
    "            cluster_rows=data_t[data_t['code_0']==cluster]\n",
    "            cluster_frequency=cluster_rows['Company'].value_counts()\n",
    "            cluster_frequency=cluster_frequency.to_frame()\n",
    "            cluster_frequency['comp_name']=cluster_frequency.index\n",
    "            cluster_frequency['Comp_Name_Std']= cluster_frequency['comp_name'][0]\n",
    "            data_tf=data_tf.append(cluster_frequency, ignore_index=True)\n",
    "        return data_tf['Comp_Name_Std'].unique(), data_tf['Comp_Name_Std'].nunique()\n",
    "    \n",
    "Step1: company_name_std is a function which takes a table as input called data_t, which has company name \"Company\", soundex code as \"code_0\" as columns\n",
    "Step2: for every unique value in that \"code_0\", subset the data for that unique values\n",
    "Step3: in that subset data create frequncy table of all unique Companies through \"Company\" column.\n",
    "Step4: assign the company with highest frquency as \"Comp_Name_Std\"\n",
    "Step5: append all this data to a table \n",
    "Step6: repeat all steps for all unique \"code_0\" values\n",
    "       Eg:step1 'Harini','Harini','Haris','xoha',\"Zen\",\"Zofa\",\"Zoha\" \n",
    "          step2  \"h123\",\"h123\",\"h123\",'z124',\"z567\",\"z124\"\n",
    "          step3  \"h123\" Frequency Table : Harini:2, Harris 1, Hence H123 -> Harini\n",
    "                 etc\n",
    "Step7: this function has to run after the soundex function runs \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3b3f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=pd.DataFrame(a,columns=['std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "797bd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\R_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "3c6a8248",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f38d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(\"C:/Users/zafreen/Downloads/df1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f0ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[['Company','code_0']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "5f8a02e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-288-17ffeaed1bff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mdf1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"code_1\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoundex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Company'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-247-7e480ad044bf>\u001b[0m in \u001b[0;36msoundex\u001b[1;34m(query)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;31m# Step 4: If the saved letterâ€™s digit is the same the resulting first digit, remove the digit (keep the letter)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mfirst_letter\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mletters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mletters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(df1)):\n",
    "    print(i)\n",
    "    df1.loc[i,\"code_1\"] = soundex(df1['Company'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b507c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3fd279dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\R_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "813ee2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1.to_csv('R.csv')\n",
    "# print(df2.shape)\n",
    "# df1.to_csv(\"R_soundex.csv\")\n",
    "# df1.head()\n",
    "# def soundex(query: str):\n",
    "#     \"\"\"\n",
    "#     https://en.wikipedia.org/wiki/Soundex\n",
    "#     :param query:\n",
    "#     :return:\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Step 0: Clean up the query string\n",
    "# #     query = query\n",
    "#     letters = [char for char in query if char.isalpha()]\n",
    "\n",
    "#     # Step 1: Save the first letter. Remove all occurrences of a, e, i, o, u, y, h, w.\n",
    "\n",
    "#     # If query contains only 1 letter, return query+\"000\" (Refer step 5)\n",
    "#     if len(query) == 1:\n",
    "#         return query + \"000\"\n",
    "\n",
    "# #    to_remove = ('a','e','i','o','u','y','h','w')\n",
    "\n",
    "\n",
    "#     first_letter = letters[0]\n",
    "# #     letters = letters[1:]\n",
    "# #     letters = [char for char in letters if char not in to_remove]\n",
    "\n",
    "# #     if len(letters) == 0:\n",
    "# #         return first_letter + \"000\"\n",
    "\n",
    "#     # Step 2: Replace all consonants (include the first letter) with digits according to rules\n",
    "\n",
    "# #     to_replace = {('b','p'): 1, ('c', 'g', 'j', 'k', 'q', 's', 'z'): 2,\n",
    "# #                   ('d', 't'): 3, ('l',): 4, ('m'):5, ('r',): 6,('f','v'): 7,( 'x'):8, ('n'): 9}\n",
    "\n",
    "#     to_replace = {('b', 'f', 'p', 'v'): 1, ('c', 'g', 'j', 'k', 'q', 's', 'x', 'z'): 2,\n",
    "#                   ('d', 't'): 3, ('l',): 4, ('m', 'n'): 5, ('r',): 6}\n",
    "\n",
    "\n",
    "#     first_letter = [value if first_letter else first_letter for group, value in to_replace.items()\n",
    "#                     if first_letter in group]\n",
    "#     letters = [value if char else char\n",
    "#                for char in letters\n",
    "#                for group, value in to_replace.items()\n",
    "#                if char in group]\n",
    "\n",
    "#     # Step 3: Replace all adjacent same digits with one digit.\n",
    "#     letters = [char for ind, char in enumerate(letters)\n",
    "#                if (ind == len(letters) - 1 or (ind+1 < len(letters) and char != letters[ind+1]))]\n",
    "\n",
    "#     # Step 4: If the saved letterâ€™s digit is the same the resulting first digit, remove the digit (keep the letter)\n",
    "#     if first_letter == letters[0]:\n",
    "#         letters[0] = query[0]\n",
    "#     else:\n",
    "#         letters.insert(0, query[0])\n",
    "\n",
    "#     # Step 5: Append 3 zeros if result contains less than 3 digits.\n",
    "#     # Remove all except first letter and 3 digits after it.\n",
    "\n",
    "#     first_letter = letters[0]\n",
    "#     letters = letters[1:]\n",
    "\n",
    "#     letters = [char for char in letters if isinstance(char, int)][0:3]\n",
    "\n",
    "#     while len(letters) < 3:\n",
    "#         letters.append(0)\n",
    "\n",
    "#     letters.insert(0, first_letter)\n",
    "\n",
    "#     string = \"\".join([str(l) for l in letters])\n",
    "\n",
    "#     return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c13116bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>first</th>\n",
       "      <th>code_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>iqvia</td>\n",
       "      <td>I210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>infor</td>\n",
       "      <td>I516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>livestyle</td>\n",
       "      <td>L123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>k</td>\n",
       "      <td>K000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>gotjunk</td>\n",
       "      <td>G325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      first code_1\n",
       "0           1      iqvia   I210\n",
       "1           2      infor   I516\n",
       "2           3  livestyle   L123\n",
       "3           4          k   K000\n",
       "4           5    gotjunk   G325"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4154b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1.rename(columns={\"first\":\"Company\",\"code_1\":\"code_0\"})\n",
    "df1=df1[['Company','code_0']]\n",
    "df1=df1.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12fdf637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>code_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>iqvia</td>\n",
       "      <td>I210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>infor</td>\n",
       "      <td>I516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>livestyle</td>\n",
       "      <td>L123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>k</td>\n",
       "      <td>K000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gotjunk</td>\n",
       "      <td>G325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Company code_0\n",
       "0      iqvia   I210\n",
       "1      infor   I516\n",
       "2  livestyle   L123\n",
       "3          k   K000\n",
       "4    gotjunk   G325"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9721c91e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "966741fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni,nuni=comp_name_std(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c060b018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5327"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nuni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6aeccf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t=df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18cf0043",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tf=pd.DataFrame()\n",
    "for cluster in data_t['code_0'].unique():\n",
    "    cluster_rows=data_t[data_t['code_0']==cluster]\n",
    "    cluster_frequency=cluster_rows['Company'].value_counts()\n",
    "    cluster_frequency=cluster_frequency.to_frame()\n",
    "    cluster_frequency['comp_name']=cluster_frequency.index\n",
    "    cluster_frequency['Comp_Name_Std']= cluster_frequency['comp_name'][0]\n",
    "    data_tf=data_tf.append(cluster_frequency, ignore_index=True)\n",
    "#  data_tf['Comp_Name_Std'].unique(), data_tf['Comp_Name_Std'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e968c9f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Comp_/name_Std'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comp_/name_Std'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-0eea071795fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata_tf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Comp_/name_Std'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Comp_/name_Std'"
     ]
    }
   ],
   "source": [
    "data_tf['Comp_/name_Std'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c469f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uni=uni.tolist()\n",
    "pd.DataFrame(data_tf).to_csv(\"Soundex_uni.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5540ed13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Company Names  Company Comp_Name_Std\n",
      "0         neoit        1         neoit\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0    nextsource        1    nextsource\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0   orthwestern        1   orthwestern\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0          stag        1          stag\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0        tarang        1        tarang\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0    tcognition        1    tcognition\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0        telent        1        telent\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0  thyssenkrupp        1  thyssenkrupp\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0       vsplash        1       vsplash\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0   voestalpine        1   voestalpine\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0         xwave        1         xwave\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0        nergie        1        nergie\n",
      "  Company Names  Company Comp_Name_Std\n",
      "0      ekerbank        1      ekerbank\n"
     ]
    }
   ],
   "source": [
    "# data_t=df1\n",
    "data_tf=pd.DataFrame()\n",
    "li=[]\n",
    "for cluster in data_t['code_0'].unique():\n",
    "    cluster_rows=data_t[data_t['code_0']==cluster]\n",
    "    cluster_frequency=cluster_rows['Company'].value_counts()\n",
    "    cluster_frequency=cluster_frequency.to_frame()\n",
    "    cluster_frequency=cluster_frequency.reset_index()\n",
    "    cluster_frequency=cluster_frequency.rename(columns={'index':'Company Names'})\n",
    "    cluster_frequency['Comp_Name_Std']= cluster_frequency['Company Names'][0]\n",
    "    data_tf=data_tf.append(cluster_frequency, ignore_index=True)\n",
    "    print(cluster_frequency)\n",
    "   \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0d4fae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d=data_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2fb7e171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9276, 2)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df1.reset_index(drop=True)\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "684f7c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9276"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4259+1474+362+150+1930+665+320+103+13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "7be252b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_t=df1[9263:]\n",
    "data_t=data_t.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "649575a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 3)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "e2f0c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_tf.to_csv(\"Fist_ENS.csv\")\n",
    "# data_tf.to_csv(\"Second.ENS.csv\")\n",
    "# data_tf.to_csv(\"Third_ENS.csv\")\n",
    "# data_tf.to_csv(\"Fourth_ENS.csv\")\n",
    "# data_tf.to_csv(\"Five_ENS.csv\")\n",
    "# data_tf.to_csv(\"Sixth_ENS.csv\")\n",
    "# data_tf.to_csv(\"Seventh_ENS.csv\")\n",
    "# data_tf.to_csv(\"Eight_ENS.csv\")\n",
    "# data_tf.to_csv(\"Ninth_ENS.csv\")\n",
    "d1=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Fist_ENS.csv\")\n",
    "d2=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Second.ENS.csv\")\n",
    "d3=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Third_ENS.csv\")\n",
    "d4=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Fourth_ENS.csv\")\n",
    "d5=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Five_ENS.csv\")\n",
    "d6=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Sixth_ENS.csv\")\n",
    "d7=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Seventh_ENS.csv\")\n",
    "d8=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Eight_ENS.csv\")\n",
    "d9=pd.read_csv(r\"C:\\Users\\zafreen\\Downloads\\ENS\\Code_ENS\\Ninth_ENS.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d288f804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9276, 4)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.concat([d1,d2,d3,d4,d5,d6,d7,d8,d9])\n",
    "data=data.reset_index(drop=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "ad980679",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=data['Comp_Name_Std'].unique()\n",
    "a.tolist()\n",
    "d1=pd.DataFrame({'Unique Companies':a})\n",
    "d1.to_csv(\"Unique Companies.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "00b0ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_name_std(data_t):\n",
    "        a=0\n",
    "        data_tf=pd.DataFrame()\n",
    "        for cluster in data_t['code_0'].unique():\n",
    "            cluster_rows=data_t[data_t['code_0']==cluster]\n",
    "            cluster_frequency=cluster_rows['Company'].value_counts()\n",
    "            cluster_frequency=cluster_frequency.to_frame()\n",
    "            cluster_frequency['comp_name']=cluster_frequency.index\n",
    "            print(cluster_frequency)\n",
    "            cluster_frequency['Comp_Name_Std']= cluster_frequency['comp_name'][0]\n",
    "            data_tf=data_tf.append(cluster_frequency, ignore_index=True)\n",
    "        return data_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccdfd49b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'comp_name_std' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-43d1fbe16b43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnew\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcomp_name_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'comp_name_std' is not defined"
     ]
    }
   ],
   "source": [
    "new=comp_name_std(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a20e811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d290ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Actual number of clusters = 76\n",
    "# Website Algorithm clustered = 19 clusters\n",
    "# Our Algorithm clustered = 57 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bb0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Pckages \n",
    "# 2) data and cleaning \n",
    "# 3) proof of 19 companies only \n",
    "# 4) Our algorithm and proof of 57 comanies - gt the external hard drive \n",
    "# Deadline 3 PM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0a5704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
