{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e70918b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zafreen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import string\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "wn=nltk.WordNetLemmatizer()\n",
    "ps=nltk.PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7cbf3978",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"C:/Users/zafreen/Downloads/spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "807e9fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "6   ham  Even my brother is not like to speak with me. ...\n",
       "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
       "8  spam  WINNER!! As a valued network customer you have...\n",
       "9  spam  Had your mobile 11 months or more? U R entitle..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)\n",
    "df=df[[\"v1\",\"v2\"]]\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7168152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import string\n",
    "# def remove_punctuation(text):\n",
    "#     text=\"\".join([char for char in text if char not in string.punctuation])\n",
    "#     return text\n",
    "# df['no_punct_text']=df['v2'].apply(lambda x:remove_punctuation(x))\n",
    "# import re\n",
    "# def tokenise(text):\n",
    "#     text=re.split(\"\\W+\",text)\n",
    "#     return text\n",
    "# df['tokenised_text']=df['no_punct_text'].apply(lambda x:tokenise(x))\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "# def remove_stopwords(text):\n",
    "#     text=[char for char in text if char not in stopwords]\n",
    "#     return text\n",
    "# df['no_stopwords_text']=df['tokenised_text'].apply(lambda x:remove_stopwords(x))\n",
    "# def lemmetize(text):\n",
    "#     text=[wn.lemmatize(char) for char in text]\n",
    "#     return text\n",
    "# df['lemmetized_text']=df['no_stopwords_text'].apply(lambda x:lemmetize(x))\n",
    "# from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# count_vector=CountVectorizer(analyzer=data_cleaning)\n",
    "# count_vector_=count_vector.fit_transform(df['v2'])\n",
    "# # print(count_vector_.shape)\n",
    "# # print(count_vector.get_feature_names())\n",
    "# dff=pd.DataFrame(count_vector_.toarray())\n",
    "# dff.columns=count_vector.get_feature_names()\n",
    "\n",
    "# tfidf_vector=TfidfVectorizer(analyzer=data_cleaning)\n",
    "# tfidf_vector_=tfidf_vector.fit_transform(df['v2'])\n",
    "# # print(tfidf_vector_.shape)\n",
    "# # print(tfidf_vector.get_feature_names())\n",
    "# df_t=pd.DataFrame(tfidf_vector_.toarray())\n",
    "# df_t.columns=tfidf_vector.get_feature_names()\n",
    "\n",
    "# ncount_vector=CountVectorizer(ngram_range=(1,2))\n",
    "# ncount_vector_=ncount_vector.fit_transform(df['v2'])\n",
    "# # print(count_vector_.shape)\n",
    "# # print(count_vector.get_feature_names())\n",
    "# df_n=pd.DataFrame(ncount_vector_.toarray())\n",
    "# df_n.columns=ncount_vector.get_feature_names()\n",
    "\n",
    "# df['text_len']=df['v2'].apply(lambda x:len(x)-x.count(\" \"))\n",
    "# def count_punctuation(text):\n",
    "#     count= sum([1 for char in text if char in string.punctuation])\n",
    "#     return round(count/(len(text)-text.count(\" \")),3)*100\n",
    "# df['Percent_punctuation']=df['v2'].apply(lambda x:count_punctuation(x))\n",
    "bins=np.linspace(0,200,40)\n",
    "pyplot.hist(df[df['v1']=='spam']['text_len'],bins,alpha=0.5,normed=True,label=\"spam\")\n",
    "pyplot.hist(df[df['v1']=='ham']['text_len'],bins,alpha=0.5,normed=True,label=\"ham\")\n",
    "pyplot.legend(loc=\"upper left\")\n",
    "pyplot.show()\n",
    "for i in [1,2,3,4,5]:\n",
    "    pyplot.hist((df['Percent_punctuation'])**(1/i),bins=40)\n",
    "    pyplot.show()\n",
    "X_features=pd.concat([df['text_len'],df['Percent_punctuation'],pd.DataFrame(tfidf_vector_.toarray())],axis=1)\n",
    "print(dir(RandomForestClassifier))\n",
    "print(RandomForestClassifier())\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier(n_jobs=-1)\n",
    "k_fold=KFold(n_splits=5)\n",
    "cross_val_score(rf,X_features,df['v1'],cv=k_fold,scoring=\"accuracy\",n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2bd045c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.05828317362129984, 'text_len'),\n",
       " (0.03814872847200637, 1799),\n",
       " (0.025343591931005514, 7331),\n",
       " (0.024629056059604457, 3127),\n",
       " (0.022122668626052736, 2027),\n",
       " (0.019954013674926736, 7162),\n",
       " (0.019812624275958216, 4780),\n",
       " (0.017646462512092172, 2167),\n",
       " (0.016714404731223126, 1357),\n",
       " (0.01609407276835166, 5709)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=50,max_depth=20,n_jobs=-1)\n",
    "rf_model=rf.fit(X_train,Y_train)\n",
    "rf_model.feature_importances_\n",
    "sorted((zip(rf_model.feature_importances_,X_train.columns)),reverse=True)[0:10]\n",
    "y_pred=rf_model.predict(x_test)\n",
    "precesion,recall,fscore,support=score(y_pred,y_test,pos_label=\"spam\",average=\"binary\")\n",
    "print(\"Precesion {} Recall {} Accuracy {}\".format(round(precesion,3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f623bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_(n_est,depth):\n",
    "    rf=RandomForestClassifier(n_estimators=n_est,max_depth=depth,n_jobs=-1)\n",
    "    rf_model=rf.fit(X_train,Y_train)\n",
    "    y_pred=rf_model.predict(x_test)\n",
    "    precesion,recall,fscore,support=score(y_pred,y_test,pos_label=\"spam\",average=\"binary\")\n",
    "    print(\"Estimators {} Max_Depth {} Precesion {} Recall {} Accuracy {}\".format(n_est,depth,round(precesion,3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e2dad216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 10 Max_Depth 10 Precesion 0.225 Recall 1.0 Accuracy 0.895\n",
      "Estimators 10 Max_Depth 20 Precesion 0.623 Recall 1.0 Accuracy 0.949\n",
      "Estimators 10 Max_Depth 30 Precesion 0.768 Recall 1.0 Accuracy 0.969\n",
      "Estimators 10 Max_Depth None Precesion 0.841 Recall 0.992 Accuracy 0.978\n",
      "Estimators 50 Max_Depth 10 Precesion 0.219 Recall 1.0 Accuracy 0.894\n",
      "Estimators 50 Max_Depth 20 Precesion 0.662 Recall 1.0 Accuracy 0.954\n",
      "Estimators 50 Max_Depth 30 Precesion 0.795 Recall 1.0 Accuracy 0.972\n",
      "Estimators 50 Max_Depth None Precesion 0.868 Recall 0.978 Accuracy 0.979\n",
      "Estimators 100 Max_Depth 10 Precesion 0.278 Recall 1.0 Accuracy 0.902\n",
      "Estimators 100 Max_Depth 20 Precesion 0.642 Recall 1.0 Accuracy 0.952\n",
      "Estimators 100 Max_Depth 30 Precesion 0.762 Recall 0.983 Accuracy 0.966\n",
      "Estimators 100 Max_Depth None Precesion 0.861 Recall 1.0 Accuracy 0.981\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10,50,100]:\n",
    "    for depth in [10,20,30,None]:\n",
    "        test_(n_est,depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "aa2d9e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ef611344",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>23.035829</td>\n",
       "      <td>0.546989</td>\n",
       "      <td>0.232988</td>\n",
       "      <td>0.004286</td>\n",
       "      <td>90</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 300}</td>\n",
       "      <td>0.976682</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.966786</td>\n",
       "      <td>0.976661</td>\n",
       "      <td>0.975053</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.275443</td>\n",
       "      <td>0.754319</td>\n",
       "      <td>0.165665</td>\n",
       "      <td>0.020927</td>\n",
       "      <td>90</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 150}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>0.003616</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.816205</td>\n",
       "      <td>0.656574</td>\n",
       "      <td>0.242755</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>None</td>\n",
       "      <td>300</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 300}</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.965889</td>\n",
       "      <td>0.974865</td>\n",
       "      <td>0.974155</td>\n",
       "      <td>0.004455</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.198190</td>\n",
       "      <td>0.031794</td>\n",
       "      <td>0.103059</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 90, 'n_estimators': 10}</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.978475</td>\n",
       "      <td>0.975763</td>\n",
       "      <td>0.964093</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973975</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.586022</td>\n",
       "      <td>0.527471</td>\n",
       "      <td>0.181488</td>\n",
       "      <td>0.015922</td>\n",
       "      <td>None</td>\n",
       "      <td>150</td>\n",
       "      <td>{'max_depth': None, 'n_estimators': 150}</td>\n",
       "      <td>0.975785</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.973968</td>\n",
       "      <td>0.967684</td>\n",
       "      <td>0.973070</td>\n",
       "      <td>0.973617</td>\n",
       "      <td>0.003347</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "8       23.035829      0.546989         0.232988        0.004286   \n",
       "7       12.275443      0.754319         0.165665        0.020927   \n",
       "11      24.816205      0.656574         0.242755        0.007691   \n",
       "6        1.198190      0.031794         0.103059        0.005862   \n",
       "10      13.586022      0.527471         0.181488        0.015922   \n",
       "\n",
       "   param_max_depth param_n_estimators  \\\n",
       "8               90                300   \n",
       "7               90                150   \n",
       "11            None                300   \n",
       "6               90                 10   \n",
       "10            None                150   \n",
       "\n",
       "                                      params  split0_test_score  \\\n",
       "8     {'max_depth': 90, 'n_estimators': 300}           0.976682   \n",
       "7     {'max_depth': 90, 'n_estimators': 150}           0.977578   \n",
       "11  {'max_depth': None, 'n_estimators': 300}           0.977578   \n",
       "6      {'max_depth': 90, 'n_estimators': 10}           0.978475   \n",
       "10  {'max_depth': None, 'n_estimators': 150}           0.975785   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "8            0.978475           0.976661           0.966786   \n",
       "7            0.977578           0.973968           0.967684   \n",
       "11           0.978475           0.973968           0.965889   \n",
       "6            0.978475           0.975763           0.964093   \n",
       "10           0.977578           0.973968           0.967684   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "8            0.976661         0.975053        0.004192                1  \n",
       "7            0.973968         0.974155        0.003616                2  \n",
       "11           0.974865         0.974155        0.004455                3  \n",
       "6            0.973070         0.973975        0.005332                4  \n",
       "10           0.973070         0.973617        0.003347                5  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier()\n",
    "params={\"n_estimators\" : [10,150,300],\"max_depth\":[30,60,90,None]}\n",
    "gs=GridSearchCV(rf,params,cv=5)\n",
    "gs_fit=gs.fit(X_features,df['v1'])\n",
    "pd.DataFrame(gs_fit.cv_results_).sort_values(\"mean_test_score\",ascending=False)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e866859",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "def test_g(n_est,depth,lr):\n",
    "    rf=GradientBoostingClassifier(n_estimators=n_est,max_depth=depth,learning_rate=lr)\n",
    "    rf_model=rf.fit(X_train,Y_train)\n",
    "    y_pred=rf_model.predict(x_test)\n",
    "    precesion,recall,fscore,support=score(y_pred,y_test,pos_label=\"spam\",average=\"binary\")\n",
    "    print(\"Estimators {} Max_Depth {} Learning rate {} Precesion {} Recall {} Accuracy {}\".format(n_est,depth,lr,round(precesion,3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c7e9fcf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 10 Max_Depth 10 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 10 Max_Depth 10 Learning rate 0.1 Precesion 0.795 Recall 0.938 Accuracy 0.965\n",
      "Estimators 10 Max_Depth 10 Learning rate 1 Precesion 0.848 Recall 0.865 Accuracy 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 10 Max_Depth 20 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 10 Max_Depth 20 Learning rate 0.1 Precesion 0.841 Recall 0.876 Accuracy 0.962\n",
      "Estimators 10 Max_Depth 20 Learning rate 1 Precesion 0.874 Recall 0.874 Accuracy 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 10 Max_Depth 30 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 10 Max_Depth 30 Learning rate 0.1 Precesion 0.841 Recall 0.864 Accuracy 0.961\n",
      "Estimators 10 Max_Depth 30 Learning rate 1 Precesion 0.874 Recall 0.841 Accuracy 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 10 Max_Depth None Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 10 Max_Depth None Learning rate 0.1 Precesion 0.841 Recall 0.87 Accuracy 0.961\n",
      "Estimators 10 Max_Depth None Learning rate 1 Precesion 0.861 Recall 0.844 Accuracy 0.96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 50 Max_Depth 10 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 50 Max_Depth 10 Learning rate 0.1 Precesion 0.861 Recall 0.909 Accuracy 0.97\n",
      "Estimators 50 Max_Depth 10 Learning rate 1 Precesion 0.828 Recall 0.874 Accuracy 0.961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 50 Max_Depth 20 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 50 Max_Depth 20 Learning rate 0.1 Precesion 0.868 Recall 0.879 Accuracy 0.966\n",
      "Estimators 50 Max_Depth 20 Learning rate 1 Precesion 0.861 Recall 0.897 Accuracy 0.968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 50 Max_Depth 30 Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 50 Max_Depth 30 Learning rate 0.1 Precesion 0.854 Recall 0.86 Accuracy 0.961\n",
      "Estimators 50 Max_Depth 30 Learning rate 1 Precesion 0.887 Recall 0.893 Accuracy 0.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zafreen\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimators 50 Max_Depth None Learning rate 0.01 Precesion 0.0 Recall 0.0 Accuracy 0.865\n",
      "Estimators 50 Max_Depth None Learning rate 0.1 Precesion 0.861 Recall 0.85 Accuracy 0.961\n",
      "Estimators 50 Max_Depth None Learning rate 1 Precesion 0.861 Recall 0.861 Accuracy 0.962\n",
      "Estimators 100 Max_Depth 10 Learning rate 0.01 Precesion 0.768 Recall 0.959 Accuracy 0.964\n",
      "Estimators 100 Max_Depth 10 Learning rate 0.1 Precesion 0.861 Recall 0.903 Accuracy 0.969\n",
      "Estimators 100 Max_Depth 10 Learning rate 1 Precesion 0.828 Recall 0.887 Accuracy 0.962\n",
      "Estimators 100 Max_Depth 20 Learning rate 0.01 Precesion 0.841 Recall 0.876 Accuracy 0.962\n",
      "Estimators 100 Max_Depth 20 Learning rate 0.1 Precesion 0.874 Recall 0.892 Accuracy 0.969\n",
      "Estimators 100 Max_Depth 20 Learning rate 1 Precesion 0.861 Recall 0.949 Accuracy 0.975\n",
      "Estimators 100 Max_Depth 30 Learning rate 0.01 Precesion 0.848 Recall 0.865 Accuracy 0.961\n",
      "Estimators 100 Max_Depth 30 Learning rate 0.1 Precesion 0.887 Recall 0.87 Accuracy 0.967\n",
      "Estimators 100 Max_Depth 30 Learning rate 1 Precesion 0.868 Recall 0.891 Accuracy 0.968\n",
      "Estimators 100 Max_Depth None Learning rate 0.01 Precesion 0.848 Recall 0.871 Accuracy 0.962\n",
      "Estimators 100 Max_Depth None Learning rate 0.1 Precesion 0.861 Recall 0.85 Accuracy 0.961\n",
      "Estimators 100 Max_Depth None Learning rate 1 Precesion 0.848 Recall 0.865 Accuracy 0.961\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10,50,100]:\n",
    "    for depth in [10,20,30,None]:\n",
    "        for lr in [0.01,0.1,1]:\n",
    "            test_g(n_est,depth,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "195fdfa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\zafreen\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_time : 0.28389787673950195\n",
      "Prediction_time : 0.040717124938964844\n",
      "Precesion 0.518 Recall 0.571 Accuracy 0.891\n",
      "fit_time : 1.2963886260986328\n",
      "Prediction_time : 0.00897979736328125\n",
      "Precesion 0.532 Recall 0.587 Accuracy 0.895\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "nltk.download('stopwords')\n",
    "from matplotlib import pyplot\n",
    "stopwords=nltk.corpus.stopwords.words(\"english\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "\n",
    "ps=nltk.PorterStemmer()\n",
    "\n",
    "df=pd.read_csv(\"C:/Users/zafreen/Downloads/spam.csv\")\n",
    "df=df[[\"v1\",\"v2\"]]\n",
    "\n",
    "def count_punctuation(text):\n",
    "    count= sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text)-text.count(\" \")),3)*100\n",
    "\n",
    "df['text_len']=df['v2'].apply(lambda x:len(x)-x.count(\" \"))\n",
    "df['Percent_punctuation']=df['v2'].apply(lambda x:count_punctuation(x))\n",
    "\n",
    "def data_cleaning(text):\n",
    "    no_punct_text=\"\".join([char for char in text if char not in string.punctuation])\n",
    "    tokenized_text=re.split(\"\\W+\",no_punct_text)\n",
    "    no_stopwords_text=[char for char in tokenized_text if char not in stopwords]\n",
    "    lemmetized_text=[ps.stem(char) for char in no_stopwords_text]\n",
    "    return lemmetized_text\n",
    "\n",
    "X_train,x_test,Y_train,y_test=train_test_split(df[['v2','text_len','Percent_punctuation']],df['v1'],test_size=0.2)\n",
    "\n",
    "tfidf_vector=TfidfVectorizer(analyzer=data_cleaning)\n",
    "tfidf_vector_fit=tfidf_vector.fit(X_train)\n",
    "\n",
    "tfidf_train=tfidf_vector_fit.transform(X_train['v2'])\n",
    "tfidf_test=tfidf_vector_fit.transform(x_test['v2'])\n",
    "X_train_vect=pd.concat([X_train[['text_len','Percent_punctuation']].reset_index(drop=True),pd.DataFrame(tfidf_train.toarray())],axis=1)\n",
    "x_test_vect=pd.concat([x_test[['text_len','Percent_punctuation']].reset_index(drop=True),pd.DataFrame(tfidf_test.toarray())],axis=1)\n",
    "\n",
    "\n",
    "rf=RandomForestClassifier(n_estimators=150,max_depth=None,n_jobs=-1)\n",
    "start=time.time()\n",
    "rf_model=rf.fit(X_train_vect,Y_train)\n",
    "end=time.time()\n",
    "print(\"fit_time : {}\".format(end-start))\n",
    "start=time.time()\n",
    "y_pred=rf_model.predict(x_test_vect)\n",
    "end=time.time()\n",
    "print(\"Prediction_time : {}\".format(end-start))\n",
    "precesion,recall,fscore,support=score(y_pred,y_test,pos_label=\"spam\",average=\"binary\")\n",
    "print(\"Precesion {} Recall {} Accuracy {}\".format(round(precesion,3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n",
    "\n",
    "\n",
    "\n",
    "rf=GradientBoostingClassifier(n_estimators=100,max_depth=11,learning_rate=0.1)\n",
    "start=time.time()\n",
    "rf_model=rf.fit(X_train_vect,Y_train)\n",
    "end=time.time()\n",
    "print(\"fit_time : {}\".format(end-start))\n",
    "start=time.time()\n",
    "y_pred=rf_model.predict(x_test_vect)\n",
    "end=time.time()\n",
    "print(\"Prediction_time : {}\".format(end-start))\n",
    "precesion,recall,fscore,support=score(y_pred,y_test,pos_label=\"spam\",average=\"binary\")\n",
    "print(\"Precesion {} Recall {} Accuracy {}\".format(round(precesion,3),round(recall,3),round((y_pred==y_test).sum()/len(y_pred),3)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf91284",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
